{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/cindy/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from master import cds_utils as utils\n",
    "# from master.cds_utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The metric for the model\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Preparing Dataset\n",
    "\n",
    "# def preprocessing(dataframe_x,labels):\n",
    "#     list_of_x=[]\n",
    "#     list_of_y=np.zeros([1,1])\n",
    "\n",
    "#     for i in dataframe_x:\n",
    "#         list_of_x.append(np.append(0,i))\n",
    "    \n",
    "#     list_of_y.fill(labels[2])\n",
    "    \n",
    "#     # reshape input to be [samples, time steps, features]\n",
    "#     list_of_x = np.reshape(list_of_x, (1, 10, 17))\n",
    "    \n",
    "#     return list_of_x,list_of_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class The_LSTM_Model:\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "    ## Preparing Dataset\n",
    "\n",
    "    def preprocessing(self, dataframe_x,labels, size, features):\n",
    "        list_of_x=[]\n",
    "        list_of_y=np.zeros([1,1])\n",
    "        \n",
    "        for i in dataframe_x.values:\n",
    "#             list_of_x.append(np.append(dat,i))\n",
    "              list_of_x.append([i])\n",
    "            \n",
    "        list_of_y.fill(labels[2])\n",
    "\n",
    "        # reshape input to be [samples, time steps, features]\n",
    "        list_of_x = np.reshape(list_of_x, (1, size, features))\n",
    "\n",
    "        return list_of_x,list_of_y\n",
    "\n",
    "    ## Training and evaluating the model\n",
    "\n",
    "    ## Train model in windows\n",
    "    def train_model(self, X_train,y_train, size):\n",
    "            # fix random seed for reproducibility\n",
    "            np.random.seed(7)\n",
    "\n",
    "            model.fit(X_train, y_train, epochs=3, batch_size=size)\n",
    "\n",
    "    ## Evaluates model based on test set\n",
    "    def evaluate_model(self, X_train,y_train,accuracy=0,iteration=0):\n",
    "\n",
    "            # Final evaluation of the model\n",
    "            scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "\n",
    "            #To get average accuracy of model\n",
    "            accuracy+=scores[1]*100\n",
    "            iteration+=1\n",
    "            prediction=model.predict(X_train)\n",
    "\n",
    "            return accuracy,iteration, prediction[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6920 - auc: 1.0000\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6869 - auc: 1.0000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6762 - auc: 1.0000\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6616 - auc: 1.0000\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6621 - auc: 1.0000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6523 - auc: 1.0000\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6345 - auc: 1.0000\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6477 - auc: 1.0000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5951 - auc: 1.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 33 into shape (1,2,11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6563dc9657fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m              \u001b[0my_is_zero\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f29fd742eca9>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(self, dataframe_x, labels, size, features)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# reshape input to be [samples, time steps, features]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlist_of_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist_of_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_of_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    255\u001b[0m            [5, 6]])\n\u001b[1;32m    256\u001b[0m     \"\"\"\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 33 into shape (1,2,11)"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    size=2\n",
    "    spl_value=0.5\n",
    "    \n",
    "    lstm_model=The_LSTM_Model()\n",
    "    # STEP 0: Check if combined dataset exists. If exists, GO TO STEP 4\n",
    "    filename = '../master/GOOGL - main.csv'\n",
    "    if os.path.isfile(filename):\n",
    "        dataset = pd.read_csv(filename, parse_dates=[0])\n",
    "        dataset.set_index('Date', inplace=True)\n",
    "    else:\n",
    "        # STEP 1:: Aggregate financial data from discrete csv files\n",
    "        #compile_financial('AAPL/')\n",
    "\n",
    "        # STEP 2: Extract csv files into pandas dataframe\n",
    "        # (1) financial dataframe\n",
    "        financial = pd.read_csv('../master/GOOGL - financial.csv', parse_dates=[1])\n",
    "        financial = interpolate_data(financial, method='zero')\n",
    "        # (2) price dataframe\n",
    "        price = pd.read_csv('../master/GOOGL - price.csv', parse_dates=[0]) # path to price \n",
    "        price.set_index('Date', inplace=True)\n",
    "        # (3) technical dataframe\n",
    "        technical = pd.read_csv('../master/GOOGL - technical.csv', parse_dates=[0])\n",
    "        technical.set_index('Date', inplace=True)\n",
    "        # camel case column names for technical\n",
    "        for old_column in technical:\n",
    "            new_column = ' '.join([word.title() for word in old_column.split('_')])\n",
    "            technical.rename(columns={old_column:new_column}, inplace=True)\n",
    "\n",
    "        # STEP 3: Join different datasets based on overlapping dates\n",
    "        dataset = combine_datasets(financial=financial, price=price, technical=technical)\n",
    "\n",
    "    # STEP 4: Split the dataset into train and test\n",
    "    train, test = utils.train_test_split(dataset, spl=spl_value)\n",
    "\n",
    "    # STEP 5: Parse the train/test dataframe into a data generator\n",
    "    data_gen = utils.data_generator(train, train_days=size, next='day')\n",
    "    i=0\n",
    "    ##100\n",
    "    ## 200\n",
    "    lstm_out=200\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_out, dropout= 0.5,return_sequences=True))\n",
    "    model.add(LSTM(200, dropout= 0.5))\n",
    "#     list_of_x = np.reshape(list_of_x, (1, 2, 17))\n",
    "    \n",
    "#     model.add(LSTM(lstm_out, dropout= 0.5,return_sequences=True))\n",
    "#     model.add(LSTM(200,dropout= 0.5, return_sequences=True))\n",
    "#     model.add(LSTM(200))\n",
    "#     model.add(LSTM(50))\n",
    "    # each 60 outputs will have a dimension of 100\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[auc])\n",
    "   \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    y_is_one=0\n",
    "    y_is_zero=0\n",
    "    \n",
    "    for x_train,y_train in data_gen:\n",
    "        \n",
    "#         print(len(x_train))\n",
    "#         print(x_train)\n",
    "        \n",
    "        features=len(x_train.columns)\n",
    "        \n",
    "        # x_train=x_train.drop(\"Quarter\",axis=1)\n",
    "#         x_train = scaler.fit_transform(x_train.values)\n",
    "        if y_train[2]==1:\n",
    "             y_is_one+=1\n",
    "        else:\n",
    "             y_is_zero+=1\n",
    "            \n",
    "        x,y=lstm_model.preprocessing(x_train, y_train,size, features)\n",
    "        \n",
    "        \n",
    "        lstm_model.train_model(x,y,size)\n",
    "#         i+=1\n",
    "#         if i >10:\n",
    "#             break\n",
    "    \n",
    "    print(y_is_one,y_is_zero)\n",
    "    \n",
    "            \n",
    "    data_gen = utils.data_generator(test, train_days=size, next='day')\n",
    "#     j=0\n",
    "    accuracy=0\n",
    "    iteration=0\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    y_true=[]\n",
    "    y_predict=[]\n",
    "    \n",
    "    for x_test,y_test in data_gen:\n",
    "#         scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#         x_test=x_test.drop(\"Quarter\",axis=1)\n",
    "#         x_test = scaler.fit_transform(x_test.values)\n",
    "\n",
    "        features=len(x_test.columns)\n",
    "        y_true.append(y_test[2])\n",
    "        x,y=lstm_model.preprocessing(x_test, y_test,size, features)\n",
    "        accuracy,iteration, prediction=lstm_model.evaluate_model(x,y,accuracy,iteration)\n",
    "        \n",
    "        y_predict.append(prediction)\n",
    "#         if prediction<=0.5:\n",
    "#             y_predict.append(0)\n",
    "#         else:\n",
    "#             y_predict.append(1)\n",
    "        \n",
    "#         j+=1\n",
    "#         if j>10:\n",
    "#             break\n",
    "    print(\"Average\")\n",
    "    print(accuracy/iteration)\n",
    "    \n",
    "    the_score=roc_auc_score(y_true, y_predict)\n",
    "    print(the_score)\n",
    "    \n",
    "#     summarize history for accuracy\n",
    "#     plt.plot(history.history['acc'])\n",
    "#     plt.plot(history.history['val_acc'])\n",
    "#     plt.title('model accuracy')\n",
    "#     plt.ylabel('accuracy')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train', 'test'], loc='upper left')\n",
    "#     plt.show()\n",
    "#     summarize history for loss\n",
    "#     plt.plot(history.history['loss'])\n",
    "#     plt.plot(history.history['val_loss'])\n",
    "#     plt.title('model loss')\n",
    "#     plt.ylabel('loss')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train', 'test'], loc='upper left')\n",
    "#     plt.show()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, y_predict).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
