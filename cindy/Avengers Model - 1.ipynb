{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/cindy/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from master import cds_utils as utils\n",
    "# from master.cds_utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing Dataset\n",
    "\n",
    "def preprocessing(dataframe_x,labels):\n",
    "    list_of_x=[]\n",
    "    list_of_y=np.zeros([1,1])\n",
    "\n",
    "    for i in dataframe_x:\n",
    "        list_of_x.append(np.append(0,i))\n",
    "    \n",
    "    list_of_y.fill(labels[2])\n",
    "    return list_of_x,list_of_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The model\n",
    "\n",
    "def model(X_train,y_train):\n",
    "        # fix random seed for reproducibility\n",
    "        np.random.seed(7)\n",
    "        \n",
    "        # reshape input to be [samples, time steps, features]\n",
    "        X_train = np.reshape(X_train, (1, 60, 17))\n",
    "\n",
    "        # create the model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(100))\n",
    "        ## each 60 outputs will have a dimension of 100\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train, epochs=3, batch_size=60)\n",
    "        #print(model.summary())\n",
    "        \n",
    "        # Final evaluation of the model\n",
    "        scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "        \n",
    "        #Just to let me know my model is working correctly\n",
    "        print(y_train)\n",
    "        print(scores)\n",
    "        print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "        prediction=model.predict(X_train)\n",
    "        print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date: 2008-09-26 00:00:00, Max date: 2018-06-29 00:00:00\n",
      "**********************************************************\n",
      "Iteration 0\n",
      "Generating (60, 17) rows of training data\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7009 - acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6277 - acc: 1.0000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5592 - acc: 1.0000\n",
      "[[1.]]\n",
      "[0.49396881461143494, 1.0]\n",
      "Accuracy: 100.00%\n",
      "[[0.6101998]]\n",
      "**********************************************************\n",
      "Iteration 1\n",
      "Generating (60, 17) rows of training data\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6684 - acc: 1.0000\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5960 - acc: 1.0000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5275 - acc: 1.0000\n",
      "[[0.]]\n",
      "[0.4610190987586975, 1.0]\n",
      "Accuracy: 100.00%\n",
      "[[0.36935937]]\n",
      "**********************************************************\n",
      "Iteration 2\n",
      "Generating (60, 17) rows of training data\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7257 - acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6534 - acc: 1.0000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5868 - acc: 1.0000\n",
      "[[1.]]\n",
      "[0.5238614082336426, 1.0]\n",
      "Accuracy: 100.00%\n",
      "[[0.5922293]]\n",
      "**********************************************************\n",
      "Iteration 3\n",
      "Generating (60, 17) rows of training data\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6637 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "## Retrieval of Raw Data\n",
    "\n",
    "# (1) financial dataframe\n",
    "financial = pd.read_csv('../master/AAPL - financial.csv', parse_dates=[1])\n",
    "financial = utils.interpolate_data(financial, method='zero')\n",
    "# (2) price dataframe\n",
    "price = pd.read_csv('../master/AAPL - price.csv', parse_dates=[0]) # path to price \n",
    "price.set_index('Date', inplace=True)\n",
    "# (3) technical dataframe\n",
    "technical = pd.read_csv('../master/AAPL - technical.csv', parse_dates=[0])\n",
    "technical.set_index('Date', inplace=True)\n",
    "# camel case column names for technical\n",
    "for old_column in technical:\n",
    "    new_column = ' '.join([word.title() for word in old_column.split('_')])\n",
    "    technical.rename(columns={old_column:new_column}, inplace=True)\n",
    "\n",
    "# Parse the dataframes into a DataGenerator\n",
    "data_generator = utils.DataGenerator(next='day', financial=financial, price=price, technical=technical)\n",
    "i=0\n",
    "for x_train,y_train in data_generator:\n",
    "#     print(x_train.to_string())\n",
    "#     print(x_train.iloc[1])\n",
    "#     print(y_train)\n",
    "#     print(x_train.columns)\n",
    "#     print(len(y_train))\n",
    "\n",
    "    # normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_train=x_train.drop(\"Quarter\",axis=1)\n",
    "    x_train = scaler.fit_transform(x_train.values)\n",
    "    x,y=preprocessing(x_train, y_train)\n",
    "\n",
    "    model(x,y)\n",
    "    i+=1\n",
    "    if i>10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Movie Example\n",
    "\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/cindy/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   19  178   32]\n",
      " [   0    0    0 ...   16  145   95]\n",
      " [   0    0    0 ...    7  129  113]\n",
      " ...\n",
      " [   0    0    0 ...    4 3586    2]\n",
      " [   0    0    0 ...   12    9   23]\n",
      " [   0    0    0 ...  204  131    9]]\n",
      "(25000, 500)\n",
      "25000\n",
      "[1 0 0 ... 0 1 0]\n",
      "25000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 168s 7ms/step - loss: 0.4790 - acc: 0.7694\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.2922 - acc: 0.8830\n",
      "Epoch 3/3\n",
      " 7680/25000 [========>.....................] - ETA: 2:33 - loss: 0.2315 - acc: 0.9116"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "print(X_train)\n",
    "print(X_train.shape)\n",
    "print(len(X_train))\n",
    "print(y_train)\n",
    "print(len(y_train))\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
